{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/bpesquet/machine-learning-katas/blob/master/notebooks/katas/workflow/ClassificationMetrics.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This is a self-correcting exercise generated by [nbgrader](https://github.com/jupyter/nbgrader). \n",
    "\n",
    "Fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Run subsequent cells to check your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kata: Code Classification Metrics From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Complete the following function to compute accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "638c7bf693d6c63be6ef30ba2713c4ad",
     "grade": false,
     "grade_id": "cell-6a21120c3e66ee57",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    nb_valid = np.absolute(1-(np.absolute(y_true - y_pred)).sum())\n",
    "    return nb_valid/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90ec2b9bb9ef31b7b663f042050f3a21",
     "grade": true,
     "grade_id": "cell-29d49954b89dc997",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([2, 0, 2, 2, 0, 1])\n",
    "y_pred = np.array([0, 1, 2, 2, 0, 2])\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy: {acc * 100:.2f}%')\n",
    "\n",
    "assert acc == 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Add other metrics: precision, recall, f1-score\n",
    "- Add confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0, 0, 0, 1, 1, 0, 1, 0, 1, 1])\n",
    "y_pred = np.array([1, 1, 0, 0, 0, 1, 1, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_true_positives(y_true, y_pred):\n",
    "    nb_true_malign = np.array(np.where(y_true==1)[0])\n",
    "    nb_pred_malign = np.array(np.where(y_pred==1)[0])\n",
    "    nb_tp = [(np.where(nb_true_malign==i)[0]) for i in nb_pred_malign]\n",
    "    nb_tp = len([i for i in nb_tp if len(i)!=0])\n",
    "    return nb_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 50.00%\n"
     ]
    }
   ],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    nb_tp = nb_true_positives(y_true, y_pred)\n",
    "    nb_tp_fp = len(np.where(y_pred==1)[0])\n",
    "    return nb_tp/nb_tp_fp\n",
    "    \n",
    "prec = precision(y_true, y_pred)\n",
    "print(f'Precision: {prec * 100:.2f}%')\n",
    "\n",
    "assert prec == 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 60.00\n"
     ]
    }
   ],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    nb_tp = nb_true_positives(y_true, y_pred)\n",
    "    nb_true_malign = len(np.array(np.where(y_true==1)[0]))\n",
    "    return nb_tp/nb_true_malign\n",
    "\n",
    "rec = recall(y_true, y_pred)\n",
    "print(f'Recall: {rec * 100:.2f}')\n",
    "\n",
    "assert rec == 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.55\n"
     ]
    }
   ],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2*(prec*rec)/(prec+rec)\n",
    "f1_score = f1_score(y_true, y_pred)\n",
    "print(f'F1_score: {f1_score:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
