{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/bpesquet/machine-learning-katas/blob/master/notebooks/katas/algorithms/DNN_ReutersNews.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This is a self-correcting exercise generated by [nbgrader](https://github.com/jupyter/nbgrader). \n",
    "\n",
    "Fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Run subsequent cells to check your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kata: Reuters News Dataset\n",
    "\n",
    "The [Reuters](https://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection) dataset is a set of short newswires and their topics, published by Reuters in 1987 and widely used for text classification. There are 46 different topics, some more represented than others. These topics are mutually exclusive: a news can only belong to one topic. \n",
    "\n",
    "The goal is to classify news articles by their topic.\n",
    "\n",
    "![Reuters logo](images/Reuters-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4deebcef4a92baf83ce9c060fd65dca9",
     "grade": false,
     "grade_id": "cell-6b04c3f881689480",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The mlkatas package contains various utility functions required by all katas\n",
    "!pip install mlkatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfc49c517cd259214122e8940a988954",
     "grade": false,
     "grade_id": "cell-7f538d5d9435b483",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Import base packages\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import mlkatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4aa5c759461a59ea28e0d3a9d424457b",
     "grade": false,
     "grade_id": "cell-655f456590cbb9cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Setup plots\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ML packages (edit this list if needed)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'Keras version: {tf.keras.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "* Load the Reuters dataset included with Keras. Limit yourself to the 10,000 most frequent words.\n",
    "* Print shapes of training data and labels.\n",
    "* Print the first training sample.\n",
    "* Print the first 10 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01a35dd4ae42736e213835d8148d608d",
     "grade": false,
     "grade_id": "cell-5e3ac2eb6ea86d5e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# The following code prevents a loading error caused by an API change in NumPy\n",
    "# https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa\n",
    "\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48609e7e57430b383681e199d77e1774",
     "grade": false,
     "grade_id": "cell-3e125eb5fc73aba4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Showing the first 10 samples as text\n",
    "\n",
    "# word_index is a dictionary mapping words to an integer index\n",
    "word_index = reuters.get_word_index()\n",
    "# We reverse it, mapping integer indices to words\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# We decode the news; note that our indices were offset by 3\n",
    "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "decoded_news = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
    "print(decoded_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Prepare data for training. Set apart the first 1,000 examples for validation. Store the data subsets in variables named `x_train`/`y_train`, `x_val`/`y_val` and `x_test`/`y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd44098580fb0679d63a43bace8576da",
     "grade": false,
     "grade_id": "cell-772c636277b2a660",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Turn news into vectors of 0s and 1s (one-hot encoding)\n",
    "x_train = mlkatas.vectorize_sequences(train_data)\n",
    "x_test = mlkatas.vectorize_sequences(test_data)\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ca71b3ccac90880f9836769e98da3f0",
     "grade": false,
     "grade_id": "cell-60a53a8850c3edc1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Show a sample of encoded input\n",
    "df_x_train = pd.DataFrame(x_train)\n",
    "df_x_train.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3de058ca81569be8ad3ff7a62ffb170d",
     "grade": true,
     "grade_id": "cell-8bc7bddaa9fcb356",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(f'x_train: {x_train.shape}. y_train: {y_train.shape}')\n",
    "print(f'x_val: {x_val.shape}. y_val: {y_val.shape}')\n",
    "print(f'x_test: {x_test.shape}. y_test: {y_test.shape}')\n",
    "\n",
    "# Assert shapes of prepared data\n",
    "assert x_train.shape == (7982, 10000)\n",
    "assert y_train.shape == (7982, 46)\n",
    "assert x_val.shape == (1000, 10000)\n",
    "assert y_val.shape == (1000, 46)\n",
    "assert x_test.shape == (2246, 10000)\n",
    "assert y_test.shape ==(2246, 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Train a model on the data to obtain a training accuracy > 95%. Store the training history in a variable named `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11d5b1334b2f3d7aa1f581b7fcf9ddc0",
     "grade": false,
     "grade_id": "cell-c7357cd3dec4e27d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3aa57e021199aa01a72b27c2797aed48",
     "grade": false,
     "grade_id": "cell-d9ed0e861fc2f12d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Show training history\n",
    "mlkatas.plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f53026a672bab4a4d4aef40250526af",
     "grade": true,
     "grade_id": "cell-cdc7a485b5d8fdfd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve final training accuracy\n",
    "train_acc = history.history['acc'][-1]\n",
    "\n",
    "# Assert final accuracy\n",
    "assert train_acc > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4502c3f8be931f3ca6b02ab6fb58467e",
     "grade": false,
     "grade_id": "cell-9ed25aeff282a0c7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate model performance on test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "If necessary, tune your model to obtain a validation accuracy > 82%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53c46527312d5ab5d23dd42f1b1e671e",
     "grade": false,
     "grade_id": "cell-a5d8dd24b58db09a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f43f21e7bd3c1f3f7dabd6f194518f8",
     "grade": false,
     "grade_id": "cell-28c316fe31702bf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Show training history\n",
    "mlkatas.plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e399464ac2181a5af21c107e889806d0",
     "grade": true,
     "grade_id": "cell-6ca80bc795d3592b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve final validation accuracy\n",
    "val_acc = history.history['val_acc'][-1]\n",
    "\n",
    "# Assert final accuracy\n",
    "assert val_acc > 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1b5b32bd4179c984e796fddd1fcf1f7",
     "grade": false,
     "grade_id": "cell-32e72a4e45c1abeb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate model performance on test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
