{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/bpesquet/machine-learning-katas/blob/master/notebooks/demos/workflow/DataPreprocessing.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Demo: Data Preprocessing with scikit-learn\n",
    "\n",
    "<https://scikit-learn.org/stable/modules/preprocessing.html>\n",
    "\n",
    "<https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html>\n",
    "\n",
    "<https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Package setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training/test set splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (30, 3)\n"
     ]
    }
   ],
   "source": [
    "# Generate a random (30,3) tensor\n",
    "x = np.random.rand(30, 3)\n",
    "test_size = .25\n",
    "\n",
    "print(f'x: {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (22, 3). x_test: (8, 3)\n"
     ]
    }
   ],
   "source": [
    "# Using scikit-learn's train_test_split() function\n",
    "x_train, x_test = model_selection.train_test_split(x, test_size=test_size)\n",
    "\n",
    "print(f'x_train: {x_train.shape}. x_test: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 8 6]\n",
      " [9 4 3]\n",
      " [3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a random (3,3) tensor with values between 1 and 10\n",
    "x = np.random.randint(1, 10, (3,3))\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Min-Max scaling\n",
    "\n",
    "Features are shifted and rescaled to the `[0,1]` range by substracting the `min` value and dividing by `(max-min)` on the first axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  1.  0.5]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]]\n",
      "Minimum: 0.0. Maximum: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Using scikit-learn's MinMaxScaler\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "print(x_scaled)\n",
    "print(f'Minimum: {x_scaled.min()}. Maximum: {x_scaled.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standardization\n",
    "\n",
    "Features are centered then reduced: substracted by their mean and divided by their standard deviation. \n",
    "\n",
    "The result has a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70710678  1.41421356  0.        ]\n",
      " [ 1.41421356 -0.70710678 -1.22474487]\n",
      " [-0.70710678 -0.70710678  1.22474487]]\n",
      "Mean: 7.401486830834377e-17. Std: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Using scikit-learn's scale() function\n",
    "x_scaled = preprocessing.scale(x)\n",
    "\n",
    "print(x_scaled)\n",
    "print(f'Mean: {x_scaled.mean()}. Std: {x_scaled.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature scaling on training/test sets\n",
    "\n",
    "To avoid information leakage, the test set must be scaled with values calculated on the training set.\n",
    "\n",
    "See https://stats.stackexchange.com/a/174865 for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Using scikit-learn's StandardScaler class\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "\n",
    "Each categorical feature with `n` possible integer values is transformed into `n` binary features, with one of them 1 and all others 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4]\n",
      " [4]\n",
      " [5]\n",
      " [8]\n",
      " [8]\n",
      " [4]\n",
      " [1]\n",
      " [8]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(0, 10, (8,1))\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Encoder input must be a matrix\n",
    "# Output will be a sparse matrix where each column corresponds to one possible value of one feature\n",
    "encoder = preprocessing.OneHotEncoder(categories='auto').fit(x)\n",
    "x_hot = encoder.transform(x).toarray()\n",
    "\n",
    "print(x_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "livereveal": {
   "scroll": true,
   "theme": "white"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
